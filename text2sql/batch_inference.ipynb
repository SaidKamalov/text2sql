{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169985a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_inference_llm import create_batch_file, push_batch_file, create_batch\n",
    "from enums import InferenceOptions\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65791c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "PROMPTS_FILE = './pipeline_results/prompts.json'\n",
    "\n",
    "INFERENCE_MODELS = [InferenceOptions.SQL_UNI, InferenceOptions.SQL_REASON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543cc64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV_MESSAGE: You are an expert SQL translator specialized in converting natural language queries into correct and efficient SQL statements.\n",
      "Pay attention to PROVIDED INFORMATION and EXAMPLES.\n",
      "If aliases for table names are needed use: T1, T2 ... as aliases!\n",
      "\n",
      "# Response Formats\n",
      "\n",
      "## response_format_schema\n",
      "{\"type\": \"object\",\"properties\": {\"sql_query\": {\"type\": \"string\",},}}\n"
     ]
    }
   ],
   "source": [
    "DEV_MESSAGE = \"You are an expert SQL translator specialized in converting natural language queries into correct and efficient SQL statements.\\n\"\n",
    "DEV_MESSAGE += \"Pay attention to PROVIDED INFORMATION and EXAMPLES.\\n\"\n",
    "DEV_MESSAGE += \"If aliases for table names are needed use: T1, T2 ... as aliases!\\n\\n\"\n",
    "DEV_MESSAGE += \"\"\"# Response Formats\\n\\n## response_format_schema\\n{\"type\": \"object\",\"properties\": {\"sql_query\": {\"type\": \"string\",},}}\"\"\"\n",
    "print(f'DEV_MESSAGE: {DEV_MESSAGE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9b8321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: openai$full_schema\n",
      "Key: reasoning$full_schema\n",
      "Key: openai$full_schema$fk\n",
      "Key: reasoning$full_schema$fk\n",
      "Key: openai$full_schema$fk$random_hardness$3\n",
      "Key: openai$full_schema$fk$random_hardness$5\n",
      "Key: openai$full_schema$fk$cosine_sim_hardness$3\n",
      "Key: openai$full_schema$fk$cosine_sim_hardness$5\n",
      "Key: reasoning$full_schema$fk$random_hardness$3\n",
      "Key: reasoning$full_schema$fk$random_hardness$5\n",
      "Key: reasoning$full_schema$fk$cosine_sim_hardness$3\n",
      "Key: reasoning$full_schema$fk$cosine_sim_hardness$5\n"
     ]
    }
   ],
   "source": [
    "with open(PROMPTS_FILE, 'r') as f:\n",
    "    list_of_dicts = json.load(f)\n",
    "\n",
    "prompt_merged_dict = {}\n",
    "for d in list_of_dicts:\n",
    "    prompt_merged_dict.update(d)\n",
    "\n",
    "for k in prompt_merged_dict.keys():\n",
    "    print(f'Key: {k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743fff9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e9c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "propmpt_type = 'reasoning$full_schema$fk$cosine_sim_hardness$3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91211199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file 'reasoning$full_schema$fk$cosine_sim_hardness$3.jsonl'created successfully. 1034 requests.\n"
     ]
    }
   ],
   "source": [
    "create_batch_file(\n",
    "    inference_option=InferenceOptions.SQL_REASON,\n",
    "    prompts=prompt_merged_dict[propmpt_type],\n",
    "    dev_message=DEV_MESSAGE,\n",
    "    file_name=propmpt_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2496d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-RSrEbMYXCEtnR9nZqTKmao', bytes=2819639, created_at=1746221178, filename='reasoning$full_schema$fk$cosine_sim_hardness$3.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "file_id = push_batch_file(propmpt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6608fc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch created:\n",
      " Batch(id='batch_6815387b89708190b22badad077c1b2e', completion_window='24h', created_at=1746221179, endpoint='/v1/responses', input_file_id='file-RSrEbMYXCEtnR9nZqTKmao', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1746307579, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'reasoning$full_schema$fk$cosine_sim_hardness$3 v0'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "batch = create_batch(file_id=file_id, description=f\"{propmpt_type} v0\")\n",
    "print(f'Batch created:\\n {batch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
