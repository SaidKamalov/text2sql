{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_llm import infer_llm\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from enums import InferenceOptions\n",
    "from utils import post_process_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "PROMPTS_FILE = './pipeline_results/prompts.json'\n",
    "\n",
    "INFERENCE_MODELS = [InferenceOptions.SQL_UNI, InferenceOptions.SQL_REASON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: openai$full_schema\n",
      "Key: reasoning$full_schema\n",
      "Key: openai$full_schema$fk\n",
      "Key: reasoning$full_schema$fk\n",
      "Key: openai$full_schema$fk$random_hardness$3\n",
      "Key: openai$full_schema$fk$random_hardness$5\n",
      "Key: openai$full_schema$fk$cosine_sim_hardness$3\n",
      "Key: openai$full_schema$fk$cosine_sim_hardness$5\n",
      "Key: reasoning$full_schema$fk$random_hardness$3\n",
      "Key: reasoning$full_schema$fk$random_hardness$5\n",
      "Key: reasoning$full_schema$fk$cosine_sim_hardness$3\n",
      "Key: reasoning$full_schema$fk$cosine_sim_hardness$5\n"
     ]
    }
   ],
   "source": [
    "with open(PROMPTS_FILE, 'r') as f:\n",
    "    list_of_dicts = json.load(f)\n",
    "\n",
    "prompt_merged_dict = {}\n",
    "for d in list_of_dicts:\n",
    "    prompt_merged_dict.update(d)\n",
    "\n",
    "for k in prompt_merged_dict.keys():\n",
    "    print(f'Key: {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to prompt mapping: {'gpt-4.1-2025-04-14': ['openai$full_schema', 'openai$full_schema$fk', 'openai$full_schema$fk$random_hardness$3', 'openai$full_schema$fk$random_hardness$5', 'openai$full_schema$fk$cosine_sim_hardness$3', 'openai$full_schema$fk$cosine_sim_hardness$5'], 'o4-mini-2025-04-16': ['reasoning$full_schema', 'reasoning$full_schema$fk', 'reasoning$full_schema$fk$random_hardness$3', 'reasoning$full_schema$fk$random_hardness$5', 'reasoning$full_schema$fk$cosine_sim_hardness$3', 'reasoning$full_schema$fk$cosine_sim_hardness$5']}\n"
     ]
    }
   ],
   "source": [
    "model_to_promp = {\n",
    "    InferenceOptions.SQL_UNI.value: [k for k in prompt_merged_dict.keys() if k.startswith('openai')], \n",
    "    InferenceOptions.SQL_REASON.value: [k for k in prompt_merged_dict.keys() if k.startswith('reasoning')]\n",
    "}\n",
    "print(f'Model to prompt mapping: {model_to_promp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV_MESSAGE: You are an expert SQL translator specialized in converting natural language queries into correct and efficient SQL statements.\n",
      "Pay attention to PROVIDED INFORMATION and EXAMPLES.\n",
      "If aliases for table names are needed use: T1, T2 ... as aliases!\n",
      "\n",
      "# Response Formats\n",
      "\n",
      "## response_format_schema\n",
      "{\"type\": \"object\",\"properties\": {\"sql_query\": {\"type\": \"string\",},}}\n"
     ]
    }
   ],
   "source": [
    "DEV_MESSAGE = \"You are an expert SQL translator specialized in converting natural language queries into correct and efficient SQL statements.\\n\"\n",
    "DEV_MESSAGE += \"Pay attention to PROVIDED INFORMATION and EXAMPLES.\\n\"\n",
    "DEV_MESSAGE += \"If aliases for table names are needed use: T1, T2 ... as aliases!\\n\\n\"\n",
    "DEV_MESSAGE += \"\"\"# Response Formats\\n\\n## response_format_schema\\n{\"type\": \"object\",\"properties\": {\"sql_query\": {\"type\": \"string\",},}}\"\"\"\n",
    "print(f'DEV_MESSAGE: {DEV_MESSAGE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring SQL queries: 100%|██████████| 1034/1034 [24:32<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "oai_prompts = prompt_merged_dict['openai$full_schema']\n",
    "oai_base_responces = infer_llm(prompts=oai_prompts, dev_message=DEV_MESSAGE, inference_option=InferenceOptions.SQL_UNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in list(oai_base_responces):\n",
    "    try:\n",
    "        responce_string = p.output[0].content[0].text\n",
    "    except:\n",
    "        responce_string = \"{'sql_query': ''}\"\n",
    "    response_dict = json.loads(responce_string)\n",
    "    pred_sql = 'SELECT '+ response_dict['sql_query']\n",
    "    pred.append(post_process_sql(pred_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './pipeline_results/dev_pred_oai_base_v0.txt'\n",
    "with open(output_file, \"w\") as f:\n",
    "    for line in pred:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n",
      "827\n"
     ]
    }
   ],
   "source": [
    "\"SELECT name FROM conductor WHERE nationality != 'USA'\"\n",
    "for i, p in enumerate(pred):\n",
    "    if p == \"SELECT name FROM conductor WHERE nationality != 'USA'\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring SQL queries: 100%|██████████| 1034/1034 [1:20:58<00:00,  4.70s/it]\n"
     ]
    }
   ],
   "source": [
    "reasoning_prompts = prompt_merged_dict['reasoning$full_schema']\n",
    "reasoning_base_responces = infer_llm(prompts=reasoning_prompts, dev_message=DEV_MESSAGE, inference_option=InferenceOptions.SQL_REASON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in list(reasoning_base_responces):\n",
    "    try:\n",
    "        responce_string = p.output_text\n",
    "        if p.output[1].content[0].text != p.output_text:\n",
    "            print(p.output[1].content[0].text)\n",
    "            print(p.output_text)\n",
    "    except:\n",
    "        # print(p.output)\n",
    "        responce_string = '{\"sql_query\": \"\"}'\n",
    "    try:\n",
    "        response_dict = json.loads(post_process_sql(responce_string))\n",
    "    except:\n",
    "        response_dict = json.loads(post_process_sql(responce_string) + '\"}')\n",
    "    pred_sql = 'SELECT '+ response_dict['sql_query']\n",
    "    pred.append(post_process_sql(pred_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.responses.response.Response'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"sql_query\":\"SELECT COUNT(*) FROM singer;\"}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(reasoning_base_responces[0]))\n",
    "reasoning_base_responces[0].output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sql_query\":\"SELECT T1.name AS stadium_name, COUNT(T2.concert_id) AS number_of_concerts FROM stadium T1 LEFT JOIN concert T2 ON T1.stadium_id = T2.stadium\n",
      "{\"sql_query\":\"SELECT T1.contid, T1.continent, COUNT(T2.countryid) AS country_count FROM continents T1 LEFT JOIN countries T2 ON T2.continent = T1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\"sql_query\":\"SELECT DISTINCT T2.model FROM cars_data AS T1 JOIN model_list AS T2 ON T1.id = T2.modelid JOIN car_makers AS T3 ON T2.maker = T3.id WHERE T1.weight < 3500 AND T3.fullname <> 'Ford Motor Company'\n",
      "\n",
      "\n",
      "{\"sql_query\":\"SELECT T1.country\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\"sql_query\":\"SELECT T1.name, T1.date\\n\n",
      "\n",
      "{\"sql_query\":\"SELECT semester_id, semester_name\\nFROM semesters\\nWHERE semester_id = (\\n  SELECT semester_id\\n  FROM student_enrolment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\"sql_query\":\"SELECT T1.id FROM tv_channel T1 JOIN tv_series T2 ON T1.id = T2.channel GROUP BY T1.id HAVING COUNT(*)\n",
      "{\"sql_query\":\"SELECT T1.money_rank\\nFROM poker_player T1\\nJOIN people T2 ON T1.people_id = T2.people_id\\nWHERE T2.height = (\\n    SELECT MAX(T3.height)\\n    FROM people T\n",
      "\n",
      "\n",
      "{\"sql_query\":\"SELECT T2.language FROM country AS T1\n",
      "{\"sql_query\":\"SELECT T1.name FROM conductor T1 JOIN orchestra T2 ON T1.conductor_id = T2.conductor_id GROUP BY T1.conductor_id, T1.name HAVING COUNT(*)\n",
      "\n",
      "{\"sql_query\":\"SELECT T1.owner_id, T2.zip_code\\nFROM (\\n    SELECT D.owner_id, SUM(T.cost_of_treatment) AS total_paid\\n    FROM treatments T\\n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in reasoning_base_responces:\n",
    "    sql_text = p.output_text\n",
    "    if not sql_text.startswith('{\"sql_query\":') or not sql_text.endswith('\"}'):\n",
    "        print(sql_text)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './pipeline_results/dev_pred_reason_base_v1.txt'\n",
    "with open(output_file, \"w\") as f:\n",
    "    for line in pred:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASE + META INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring SQL queries: 100%|██████████| 1034/1034 [27:54<00:00,  1.62s/it] \n"
     ]
    }
   ],
   "source": [
    "oai_base_meta_prompts = prompt_merged_dict['openai$full_schema$fk']\n",
    "oai_base_meta_responces = infer_llm(prompts=oai_base_meta_prompts, dev_message=DEV_MESSAGE, inference_option=InferenceOptions.SQL_UNI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in list(oai_base_meta_responces):\n",
    "    try:\n",
    "        responce_string = p.output[0].content[0].text\n",
    "    except:\n",
    "        responce_string = \"{'sql_query': ''}\"\n",
    "    response_dict = json.loads(responce_string)\n",
    "    pred_sql = 'SELECT '+ response_dict['sql_query']\n",
    "    pred.append(post_process_sql(pred_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './pipeline_results/dev_pred_oai_base_meta_v0.txt'\n",
    "with open(output_file, \"w\") as f:\n",
    "    for line in pred:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE + META INFO + EXAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI + random by hardness k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring SQL queries: 100%|██████████| 1034/1034 [24:07<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "oai_base_meta_rand_hard_3_prompts = prompt_merged_dict['openai$full_schema$fk$random_hardness$3']\n",
    "oai_base_meta_rand_hard_3_responces = infer_llm(prompts=oai_base_meta_rand_hard_3_prompts, dev_message=DEV_MESSAGE, inference_option=InferenceOptions.SQL_UNI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in list(oai_base_meta_rand_hard_3_responces):\n",
    "    try:\n",
    "        responce_string = p.output[0].content[0].text\n",
    "    except:\n",
    "        responce_string = \"{'sql_query': ''}\"\n",
    "    response_dict = json.loads(responce_string)\n",
    "    pred_sql = 'SELECT '+ response_dict['sql_query']\n",
    "    pred.append(post_process_sql(pred_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './pipeline_results/dev_pred_oai_base_meta_rand_hard_3_v0.txt'\n",
    "with open(output_file, \"w\") as f:\n",
    "    for line in pred:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI + random by hardness k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring SQL queries: 100%|██████████| 1034/1034 [24:07<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "oai_base_meta_rand_hard_5_prompts = prompt_merged_dict['openai$full_schema$fk$random_hardness$5']\n",
    "oai_base_meta_rand_hard_5_responces = infer_llm(prompts=oai_base_meta_rand_hard_5_prompts, dev_message=DEV_MESSAGE, inference_option=InferenceOptions.SQL_UNI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for p in list(oai_base_meta_rand_hard_5_responces):\n",
    "    try:\n",
    "        responce_string = p.output[0].content[0].text\n",
    "    except:\n",
    "        responce_string = \"{'sql_query': ''}\"\n",
    "    response_dict = json.loads(responce_string)\n",
    "    pred_sql = 'SELECT '+ response_dict['sql_query']\n",
    "    pred.append(post_process_sql(pred_sql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './pipeline_results/dev_pred_oai_base_meta_rand_hard_5_v0.txt'\n",
    "with open(output_file, \"w\") as f:\n",
    "    for line in pred:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
